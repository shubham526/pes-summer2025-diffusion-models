{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f780b05",
   "metadata": {},
   "source": [
    "# Lab 6: Conditional Generation - From Random to Controllable\n",
    "**Course: Diffusion Models: Theory and Applications**  \n",
    "**Duration: 90 minutes**  \n",
    "**Team Size: 2 students (same teams from Labs 1-5)**\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lab, students will be able to:\n",
    "1. **Implement** class-conditional diffusion models with embedding injection\n",
    "2. **Build** classifier guidance systems for external steering during sampling\n",
    "3. **Create** classifier-free guidance (CFG) for modern conditional generation\n",
    "4. **Construct** U-Net modifications for conditioning at multiple scales\n",
    "5. **Analyze** trade-offs between conditioning approaches in terms of quality, speed, and flexibility\n",
    "6. **Deploy** conditional generation systems for practical creative applications\n",
    "\n",
    "---\n",
    "\n",
    "## Lab Setup and Conditional Generation Framework\n",
    "\n",
    "### Part 1: Team Setup & Conditional Generation Mission (10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414951df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional generation implementation setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.distributions import Normal\n",
    "from typing import Tuple, Dict, List, Optional, Union\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set seeds for reproducible conditional generation\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Conditional generation experiments on: {device}\")\n",
    "\n",
    "@dataclass\n",
    "class ConditionalConfig:\n",
    "    \"\"\"Configuration for conditional generation experiments\"\"\"\n",
    "    T: int = 50\n",
    "    beta_start: float = 1e-4\n",
    "    beta_end: float = 2e-2\n",
    "    img_size: int = 32\n",
    "    channels: int = 1\n",
    "    num_classes: int = 4\n",
    "    dropout_prob: float = 0.1  # For classifier-free guidance training\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        # Compute noise schedule\n",
    "        self.betas = torch.linspace(self.beta_start, self.beta_end, self.T).to(device)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = torch.cat([torch.ones(1).to(device), self.alphas_cumprod[:-1]])\n",
    "\n",
    "# Create conditional configuration\n",
    "config = ConditionalConfig(T=50, img_size=8, channels=1, num_classes=4)\n",
    "print(f\"Conditional config: T={config.T}, classes={config.num_classes}, image_size={config.img_size}x{config.img_size}\")\n",
    "\n",
    "# Create synthetic dataset with class labels for conditioning experiments\n",
    "def create_conditional_dataset(n_samples_per_class: int = 50) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Create 2D dataset with clear class structure for conditional generation\"\"\"\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Class 0: Circle in top-right\n",
    "    t = torch.linspace(0, 2*math.pi, n_samples_per_class)\n",
    "    x = 2 + 0.8 * torch.cos(t) + 0.1 * torch.randn(n_samples_per_class)\n",
    "    y = 2 + 0.8 * torch.sin(t) + 0.1 * torch.randn(n_samples_per_class)\n",
    "    all_data.append(torch.stack([x, y], dim=1))\n",
    "    all_labels.extend([0] * n_samples_per_class)\n",
    "    \n",
    "    # Class 1: Square in top-left\n",
    "    x = -2 + 1.6 * torch.rand(n_samples_per_class) - 0.8 + 0.1 * torch.randn(n_samples_per_class)\n",
    "    y = 2 + 1.6 * torch.rand(n_samples_per_class) - 0.8 + 0.1 * torch.randn(n_samples_per_class)\n",
    "    all_data.append(torch.stack([x, y], dim=1))\n",
    "    all_labels.extend([1] * n_samples_per_class)\n",
    "    \n",
    "    # Class 2: Triangle in bottom-left\n",
    "    for i in range(n_samples_per_class):\n",
    "        # Random point in triangle\n",
    "        r1, r2 = torch.rand(2)\n",
    "        if r1 + r2 > 1:\n",
    "            r1, r2 = 1 - r1, 1 - r2\n",
    "        x = -2 + r1 * 1.6\n",
    "        y = -2 + r2 * 1.6\n",
    "        all_data.append(torch.tensor([[x + 0.1 * torch.randn(1), y + 0.1 * torch.randn(1)]]))\n",
    "        all_labels.append(2)\n",
    "    \n",
    "    # Class 3: Line in bottom-right\n",
    "    x = 1.2 + 1.6 * torch.rand(n_samples_per_class) + 0.1 * torch.randn(n_samples_per_class)\n",
    "    y = -2.5 + 0.1 * x + 0.2 * torch.randn(n_samples_per_class)\n",
    "    all_data.append(torch.stack([x, y], dim=1))\n",
    "    all_labels.extend([3] * n_samples_per_class)\n",
    "    \n",
    "    # Combine all data\n",
    "    if len(all_data) > 3:\n",
    "        # Handle the triangle case\n",
    "        triangle_data = torch.cat([item for item in all_data if len(item.shape) == 2 and item.shape[0] == 1])\n",
    "        other_data = [item for item in all_data if len(item.shape) == 2 and item.shape[0] > 1]\n",
    "        other_data.append(triangle_data)\n",
    "        data = torch.cat(other_data, dim=0)\n",
    "    else:\n",
    "        data = torch.cat(all_data, dim=0)\n",
    "    \n",
    "    labels = torch.tensor(all_labels)\n",
    "    \n",
    "    return data.to(device), labels.to(device)\n",
    "\n",
    "# Create dataset\n",
    "train_data, train_labels = create_conditional_dataset(60)\n",
    "print(f\"Dataset shape: {train_data.shape}, Labels shape: {train_labels.shape}\")\n",
    "\n",
    "# Visualize dataset with class colors\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "class_names = ['Circle', 'Square', 'Triangle', 'Line']\n",
    "\n",
    "for class_id in range(config.num_classes):\n",
    "    class_mask = train_labels == class_id\n",
    "    class_data = train_data[class_mask]\n",
    "    plt.scatter(class_data[:, 0].cpu(), class_data[:, 1].cpu(), \n",
    "               c=colors[class_id], label=f'Class {class_id}: {class_names[class_id]}', \n",
    "               alpha=0.7, s=50)\n",
    "\n",
    "plt.title('Conditional Dataset: 4 Distinct Classes')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Conditional dataset created with clear class structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f2f73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Understanding Unconditional Limitations (10 minutes)\n",
    "\n",
    "### Task 2.1: Demonstrate Unconditional Generation Problems\n",
    "\n",
    "**Your Mission**: Show why unconditional generation is insufficient for practical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnconditionalLimitations:\n",
    "    \"\"\"\n",
    "    Demonstrate the fundamental limitations of unconditional diffusion models.\n",
    "    This motivates the need for conditional generation approaches.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, unconditional_model: nn.Module, config: ConditionalConfig):\n",
    "        self.model = unconditional_model\n",
    "        self.config = config\n",
    "        \n",
    "    def demonstrate_random_generation_problem(self, n_samples: int = 100):\n",
    "        \"\"\"\n",
    "        Show how unconditional generation produces random samples from the full distribution\n",
    "        \"\"\"\n",
    "        print(\"=== Unconditional Generation Problem ===\\n\")\n",
    "        \n",
    "        # Simulate unconditional sampling (we'll use a simple approach for demonstration)\n",
    "        print(\"Generating unconditional samples...\")\n",
    "        \n",
    "        # Create a simple mixture of the training data for demonstration\n",
    "        samples = []\n",
    "        for _ in range(n_samples):\n",
    "            # Randomly pick a data point and add some noise (simulating unconditional generation)\n",
    "            idx = torch.randint(0, len(train_data), (1,))\n",
    "            base_sample = train_data[idx]\n",
    "            noise = 0.3 * torch.randn_like(base_sample)\n",
    "            sample = base_sample + noise\n",
    "            samples.append(sample)\n",
    "        \n",
    "        unconditional_samples = torch.cat(samples, dim=0)\n",
    "        \n",
    "        # Visualize the problem\n",
    "        self.visualize_unconditional_problem(unconditional_samples)\n",
    "        \n",
    "        return unconditional_samples\n",
    "    \n",
    "    def visualize_unconditional_problem(self, unconditional_samples: torch.Tensor):\n",
    "        \"\"\"Visualize why unconditional generation is problematic\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Original data with classes\n",
    "        colors = ['red', 'blue', 'green', 'orange']\n",
    "        class_names = ['Circle', 'Square', 'Triangle', 'Line']\n",
    "        \n",
    "        for class_id in range(config.num_classes):\n",
    "            class_mask = train_labels == class_id\n",
    "            class_data = train_data[class_mask]\n",
    "            axes[0].scatter(class_data[:, 0].cpu(), class_data[:, 1].cpu(), \n",
    "                           c=colors[class_id], label=f'{class_names[class_id]}', \n",
    "                           alpha=0.7, s=50)\n",
    "        \n",
    "        axes[0].set_title('Original Data\\n(Clear Class Structure)')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        axes[0].axis('equal')\n",
    "        \n",
    "        # Unconditional samples (mixed)\n",
    "        axes[1].scatter(unconditional_samples[:, 0].cpu(), unconditional_samples[:, 1].cpu(), \n",
    "                       c='gray', alpha=0.6, s=30)\n",
    "        axes[1].set_title('Unconditional Generation\\n(Random Mix)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        axes[1].axis('equal')\n",
    "        \n",
    "        # What we want: conditional control\n",
    "        axes[2].text(0.5, 0.7, 'WHAT WE WANT:', ha='center', va='center', \n",
    "                    fontsize=14, fontweight='bold', transform=axes[2].transAxes)\n",
    "        axes[2].text(0.5, 0.5, '\"Generate a Circle\"', ha='center', va='center', \n",
    "                    fontsize=12, color='red', transform=axes[2].transAxes)\n",
    "        axes[2].text(0.5, 0.4, '\"Generate a Square\"', ha='center', va='center', \n",
    "                    fontsize=12, color='blue', transform=axes[2].transAxes)\n",
    "        axes[2].text(0.5, 0.3, '\"Generate a Triangle\"', ha='center', va='center', \n",
    "                    fontsize=12, color='green', transform=axes[2].transAxes)\n",
    "        axes[2].text(0.5, 0.1, 'CONTROLLED GENERATION!', ha='center', va='center', \n",
    "                    fontsize=14, fontweight='bold', color='purple', transform=axes[2].transAxes)\n",
    "        axes[2].set_title('Desired: Conditional Control')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"The Problem:\")\n",
    "        print(\"‚Ä¢ Unconditional generation gives random samples from the full distribution\")\n",
    "        print(\"‚Ä¢ No control over what specific content is generated\")\n",
    "        print(\"‚Ä¢ Must generate many samples to find desired content\")\n",
    "        print(\"‚Ä¢ Wastes computation and provides poor user experience\")\n",
    "        print(\"\\nThe Solution: Replace p(x) with p(x|y) where y is our condition!\")\n",
    "    \n",
    "    def analyze_generation_efficiency(self, target_class: int = 0, max_attempts: int = 50):\n",
    "        \"\"\"\n",
    "        Analyze how many unconditional samples we need to get desired class\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== Efficiency Analysis: Finding Class {target_class} ===\\n\")\n",
    "        \n",
    "        # Simulate trying to find samples of target class through unconditional generation\n",
    "        attempts = 0\n",
    "        target_found = 0\n",
    "        target_samples = []\n",
    "        \n",
    "        # Simple classifier to determine which class a sample belongs to\n",
    "        def classify_sample(sample):\n",
    "            \"\"\"Simple distance-based classifier for our synthetic data\"\"\"\n",
    "            # Class centers (approximate)\n",
    "            centers = torch.tensor([\n",
    "                [2.0, 2.0],   # Circle\n",
    "                [-2.0, 2.0],  # Square  \n",
    "                [-2.0, -2.0], # Triangle\n",
    "                [2.0, -2.5]   # Line\n",
    "            ]).to(device)\n",
    "            \n",
    "            distances = torch.norm(sample - centers, dim=1)\n",
    "            return torch.argmin(distances).item()\n",
    "        \n",
    "        while attempts < max_attempts and target_found < 10:\n",
    "            # Generate unconditional sample\n",
    "            idx = torch.randint(0, len(train_data), (1,))\n",
    "            base_sample = train_data[idx]\n",
    "            noise = 0.3 * torch.randn_like(base_sample)\n",
    "            sample = base_sample + noise\n",
    "            \n",
    "            attempts += 1\n",
    "            \n",
    "            # Check if it's the target class\n",
    "            predicted_class = classify_sample(sample.squeeze())\n",
    "            if predicted_class == target_class:\n",
    "                target_found += 1\n",
    "                target_samples.append(sample)\n",
    "        \n",
    "        success_rate = target_found / attempts\n",
    "        print(f\"Attempts: {attempts}\")\n",
    "        print(f\"Target class samples found: {target_found}\")\n",
    "        print(f\"Success rate: {success_rate:.2%}\")\n",
    "        print(f\"Average attempts per target sample: {attempts/max(target_found, 1):.1f}\")\n",
    "        \n",
    "        print(f\"\\nüí° Insight: Unconditional generation is inefficient!\")\n",
    "        print(f\"   With conditional generation, we could generate target samples directly!\")\n",
    "        \n",
    "        return success_rate\n",
    "\n",
    "# Simple unconditional model simulation\n",
    "class SimpleUnconditionalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 64),  # 2D data + 1 time dimension\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        t_embed = t.float().unsqueeze(-1) / config.T\n",
    "        input_with_time = torch.cat([x, t_embed], dim=-1)\n",
    "        return self.net(input_with_time)\n",
    "\n",
    "# Test unconditional limitations\n",
    "unconditional_model = SimpleUnconditionalModel().to(device)\n",
    "limitations_demo = UnconditionalLimitations(unconditional_model, config)\n",
    "\n",
    "# Demonstrate the problems\n",
    "unconditional_samples = limitations_demo.demonstrate_random_generation_problem(n_samples=80)\n",
    "efficiency = limitations_demo.analyze_generation_efficiency(target_class=0, max_attempts=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd59be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Class-Conditional Diffusion Implementation (25 minutes)\n",
    "\n",
    "### Task 3.1: Implement Class-Conditional U-Net\n",
    "\n",
    "**Your Mission**: Build the simplest form of conditional generation using class embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassConditionalUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple U-Net-style network with class conditioning.\n",
    "    This demonstrates the basic approach to conditional generation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dim: int = 2, num_classes: int = 4, embed_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.data_dim = data_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Class embedding table\n",
    "        self.class_embedding = nn.Embedding(num_classes, embed_dim)\n",
    "        \n",
    "        # Time embedding (simple version)\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "        \n",
    "        # Main network - simplified U-Net structure\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(data_dim + embed_dim, 128),  # data + combined embedding\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128 + embed_dim, 128),  # features + combined embedding\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, data_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, class_labels: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass with class conditioning\n",
    "        \n",
    "        Args:\n",
    "            x: Noisy data [batch_size, data_dim]\n",
    "            class_labels: Class labels [batch_size] or None for unconditional\n",
    "            t: Timesteps [batch_size]\n",
    "            \n",
    "        Returns:\n",
    "            Predicted noise [batch_size, data_dim]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Handle timestep\n",
    "        if t.dim() == 0:\n",
    "            t = t.repeat(batch_size)\n",
    "        t_embed = self.time_mlp(t.float().unsqueeze(-1) / config.T)\n",
    "        \n",
    "        # Handle class conditioning\n",
    "        if class_labels is not None:\n",
    "            class_embed = self.class_embedding(class_labels)\n",
    "            # Combine time and class embeddings\n",
    "            combined_embed = t_embed + class_embed\n",
    "        else:\n",
    "            # Unconditional case\n",
    "            combined_embed = t_embed\n",
    "        \n",
    "        # Encoder path\n",
    "        x_with_embed = torch.cat([x, combined_embed], dim=-1)\n",
    "        encoded = self.encoder(x_with_embed)\n",
    "        \n",
    "        # Decoder path\n",
    "        decoder_input = torch.cat([encoded, combined_embed], dim=-1)\n",
    "        output = self.decoder(decoder_input)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class ClassConditionalTrainer:\n",
    "    \"\"\"\n",
    "    Training system for class-conditional diffusion models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: ClassConditionalUNet, config: ConditionalConfig):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.model.train()\n",
    "        \n",
    "    def add_noise(self, x_start: torch.Tensor, t: torch.Tensor, noise: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Add noise according to the forward process\"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        \n",
    "        alpha_cumprod_t = self.config.alphas_cumprod[t]\n",
    "        if alpha_cumprod_t.dim() == 0:\n",
    "            alpha_cumprod_t = alpha_cumprod_t.unsqueeze(0)\n",
    "        if alpha_cumprod_t.shape[0] != x_start.shape[0]:\n",
    "            alpha_cumprod_t = alpha_cumprod_t.repeat(x_start.shape[0])\n",
    "        \n",
    "        alpha_cumprod_t = alpha_cumprod_t.view(-1, 1)\n",
    "        \n",
    "        x_noisy = torch.sqrt(alpha_cumprod_t) * x_start + torch.sqrt(1 - alpha_cumprod_t) * noise\n",
    "        return x_noisy, noise\n",
    "    \n",
    "    def training_step(self, x_batch: torch.Tensor, class_batch: torch.Tensor) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        TODO: Implement class-conditional training step\n",
    "        \n",
    "        Implement the class-conditional diffusion training objective:\n",
    "        L = E[||Œµ - Œµ_Œ∏(x_t, y, t)||¬≤]\n",
    "        \n",
    "        Steps:\n",
    "        1. Sample random timesteps t for each item in batch\n",
    "        2. Sample noise Œµ from N(0, I)\n",
    "        3. Create noisy data x_t using forward process\n",
    "        4. Predict noise using model with class conditioning\n",
    "        5. Compute MSE loss between predicted and actual noise\n",
    "        6. Return loss and metrics\n",
    "        \n",
    "        Args:\n",
    "            x_batch: Clean data batch [batch_size, data_dim]\n",
    "            class_batch: Class labels [batch_size]\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with 'loss' and other metrics\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        # Hint: Use self.add_noise() and self.model()\n",
    "        # Remember to sample timesteps uniformly from [0, T-1]\n",
    "        pass\n",
    "    \n",
    "    def train_epoch(self, data: torch.Tensor, labels: torch.Tensor, \n",
    "                   batch_size: int = 32, lr: float = 1e-3) -> List[float]:\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        losses = []\n",
    "        \n",
    "        n_batches = len(data) // batch_size\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, len(data))\n",
    "            \n",
    "            x_batch = data[start_idx:end_idx]\n",
    "            class_batch = labels[start_idx:end_idx]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            try:\n",
    "                result = self.training_step(x_batch, class_batch)\n",
    "                if result and 'loss' in result:\n",
    "                    loss = result['loss']\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    losses.append(loss.item())\n",
    "                else:\n",
    "                    print(f\"Batch {i}: Implement training_step() method\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Batch {i}: Error in training - {e}\")\n",
    "                break\n",
    "        \n",
    "        return losses\n",
    "\n",
    "class ClassConditionalSampler:\n",
    "    \"\"\"\n",
    "    Sampling system for class-conditional diffusion models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: ClassConditionalUNet, config: ConditionalConfig):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.model.eval()\n",
    "    \n",
    "    def ddim_step(self, x_t: torch.Tensor, class_labels: torch.Tensor, t: int, s: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        TODO: Implement class-conditional DDIM sampling step\n",
    "        \n",
    "        Perform one step of class-conditional DDIM sampling.\n",
    "        \n",
    "        Steps:\n",
    "        1. Predict noise using the model with class conditioning\n",
    "        2. Predict clean data x_0 from current state and predicted noise\n",
    "        3. Compute the DDIM update: x_s = ‚àö·æ±_s * xÃÇ_0 + ‚àö(1-·æ±_s) * ŒµÃÇ\n",
    "        4. Return the updated state\n",
    "        \n",
    "        Args:\n",
    "            x_t: Current noisy state [batch_size, data_dim]\n",
    "            class_labels: Target class labels [batch_size]\n",
    "            t: Current timestep\n",
    "            s: Target timestep (s < t)\n",
    "            \n",
    "        Returns:\n",
    "            x_s: Updated state [batch_size, data_dim]\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        # Hint: Use self.model() for noise prediction\n",
    "        # Remember the DDIM formulas from Lab 5\n",
    "        pass\n",
    "    \n",
    "    def sample_class_conditional(self, class_labels: torch.Tensor, num_steps: int = 20) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        TODO: Implement complete class-conditional sampling\n",
    "        \n",
    "        Generate samples conditioned on specific class labels.\n",
    "        \n",
    "        Steps:\n",
    "        1. Create timestep schedule (uniform spacing)\n",
    "        2. Initialize x_T from pure noise\n",
    "        3. For each timestep pair (t, s): apply ddim_step\n",
    "        4. Return final samples\n",
    "        \n",
    "        Args:\n",
    "            class_labels: Desired class labels [batch_size]\n",
    "            num_steps: Number of sampling steps\n",
    "            \n",
    "        Returns:\n",
    "            Generated samples [batch_size, data_dim]\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        # Hint: Create uniform timestep schedule like in Lab 5\n",
    "        # Use ddim_step() for each sampling step\n",
    "        pass\n",
    "    \n",
    "    def create_timestep_schedule(self, num_steps: int) -> List[int]:\n",
    "        \"\"\"Create uniform timestep schedule\"\"\"\n",
    "        step_size = self.config.T // num_steps\n",
    "        timesteps = list(range(self.config.T - 1, -1, -step_size))\n",
    "        timesteps.append(0)\n",
    "        return timesteps[:num_steps + 1]\n",
    "    \n",
    "    def demonstrate_class_conditional_generation(self, samples_per_class: int = 15, num_steps: int = 20):\n",
    "        \"\"\"Demonstrate conditional generation for all classes\"\"\"\n",
    "        print(\"=== Class-Conditional Generation Demo ===\\n\")\n",
    "        \n",
    "        all_samples = []\n",
    "        all_class_labels = []\n",
    "        \n",
    "        for class_id in range(self.config.num_classes):\n",
    "            print(f\"Generating class {class_id} samples...\")\n",
    "            \n",
    "            # Create class labels for this class\n",
    "            class_labels = torch.full((samples_per_class,), class_id, dtype=torch.long).to(device)\n",
    "            \n",
    "            try:\n",
    "                # Generate samples\n",
    "                samples = self.sample_class_conditional(class_labels, num_steps)\n",
    "                \n",
    "                if samples is not None:\n",
    "                    all_samples.append(samples)\n",
    "                    all_class_labels.extend([class_id] * samples_per_class)\n",
    "                    print(f\"  ‚úì Generated {samples_per_class} samples for class {class_id}\")\n",
    "                else:\n",
    "                    print(f\"  ‚ùå Implement sample_class_conditional() method\")\n",
    "                    return None, None\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error generating class {class_id}: {e}\")\n",
    "                return None, None\n",
    "        \n",
    "        if all_samples:\n",
    "            generated_samples = torch.cat(all_samples, dim=0)\n",
    "            generated_labels = torch.tensor(all_class_labels)\n",
    "            \n",
    "            self.visualize_conditional_results(generated_samples, generated_labels)\n",
    "            return generated_samples, generated_labels\n",
    "        \n",
    "        return None, None\n",
    "    \n",
    "    def visualize_conditional_results(self, samples: torch.Tensor, labels: torch.Tensor):\n",
    "        \"\"\"Visualize class-conditional generation results\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        colors = ['red', 'blue', 'green', 'orange']\n",
    "        class_names = ['Circle', 'Square', 'Triangle', 'Line']\n",
    "        \n",
    "        # Original training data\n",
    "        for class_id in range(self.config.num_classes):\n",
    "            class_mask = train_labels == class_id\n",
    "            class_data = train_data[class_mask]\n",
    "            axes[0].scatter(class_data[:, 0].cpu(), class_data[:, 1].cpu(), \n",
    "                           c=colors[class_id], label=f'{class_names[class_id]}', \n",
    "                           alpha=0.7, s=50)\n",
    "        \n",
    "        axes[0].set_title('Original Training Data')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        axes[0].axis('equal')\n",
    "        \n",
    "        # Generated conditional samples\n",
    "        for class_id in range(self.config.num_classes):\n",
    "            class_mask = labels == class_id\n",
    "            if class_mask.any():\n",
    "                class_samples = samples[class_mask]\n",
    "                axes[1].scatter(class_samples[:, 0].cpu(), class_samples[:, 1].cpu(), \n",
    "                               c=colors[class_id], label=f'{class_names[class_id]}', \n",
    "                               alpha=0.7, s=50)\n",
    "        \n",
    "        axes[1].set_title('Generated Conditional Samples')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        axes[1].axis('equal')\n",
    "        \n",
    "        # Individual class generations\n",
    "        axes[2].text(0.5, 0.8, 'Class-Conditional Success!', ha='center', va='center', \n",
    "                    fontsize=14, fontweight='bold', transform=axes[2].transAxes)\n",
    "        axes[2].text(0.5, 0.6, '‚úì Generate specific classes on demand', ha='center', va='center', \n",
    "                    fontsize=11, transform=axes[2].transAxes)\n",
    "        axes[2].text(0.5, 0.5, '‚úì No random sampling required', ha='center', va='center', \n",
    "                    fontsize=11, transform=axes[2].transAxes)\n",
    "        axes[2].text(0.5, 0.4, '‚úì Direct control over generation', ha='center', va='center', \n",
    "                    fontsize=11, transform=axes[2].transAxes)\n",
    "        axes[2].text(0.5, 0.2, 'Simple & Effective!', ha='center', va='center', \n",
    "                    fontsize=12, fontweight='bold', color='green', transform=axes[2].transAxes)\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create and test class-conditional model\n",
    "print(\"Creating class-conditional model...\")\n",
    "class_conditional_model = ClassConditionalUNet(data_dim=2, num_classes=config.num_classes).to(device)\n",
    "\n",
    "# Test training system\n",
    "trainer = ClassConditionalTrainer(class_conditional_model, config)\n",
    "\n",
    "# Quick training demonstration (just a few steps for this lab)\n",
    "print(\"\\nQuick training demonstration...\")\n",
    "losses = trainer.train_epoch(train_data, train_labels, batch_size=16, lr=1e-3)\n",
    "if losses:\n",
    "    print(f\"Training losses: {losses[:5]}...\")  # Show first few losses\n",
    "    \n",
    "    # Test sampling\n",
    "    sampler = ClassConditionalSampler(class_conditional_model, config)\n",
    "    generated_samples, generated_labels = sampler.demonstrate_class_conditional_generation(\n",
    "        samples_per_class=12, num_steps=20)\n",
    "else:\n",
    "    print(\"‚ùå Implement training_step() to proceed with sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bb219a",
   "metadata": {},
   "source": [
    "### Task 3.2: Analyze Class-Conditional Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61483c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassConditionalAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze the performance and characteristics of class-conditional generation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sampler: ClassConditionalSampler):\n",
    "        self.sampler = sampler\n",
    "        \n",
    "    def analyze_class_separation(self, samples_per_class: int = 20):\n",
    "        \"\"\"Analyze how well the model separates different classes\"\"\"\n",
    "        print(\"=== Class Separation Analysis ===\\n\")\n",
    "        \n",
    "        # Generate samples for each class\n",
    "        class_samples = {}\n",
    "        \n",
    "        for class_id in range(config.num_classes):\n",
    "            class_labels = torch.full((samples_per_class,), class_id, dtype=torch.long).to(device)\n",
    "            \n",
    "            try:\n",
    "                samples = self.sampler.sample_class_conditional(class_labels, num_steps=20)\n",
    "                if samples is not None:\n",
    "                    class_samples[class_id] = samples\n",
    "                    print(f\"‚úì Generated class {class_id} samples\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Implement sampling methods first\")\n",
    "                    return\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error generating class {class_id}: {e}\")\n",
    "                return\n",
    "        \n",
    "        # Compute class centers and inter-class distances\n",
    "        self.compute_class_statistics(class_samples)\n",
    "        \n",
    "    def compute_class_statistics(self, class_samples: Dict[int, torch.Tensor]):\n",
    "        \"\"\"Compute statistics about class separation\"\"\"\n",
    "        class_centers = {}\n",
    "        class_spreads = {}\n",
    "        \n",
    "        print(\"Class Statistics:\")\n",
    "        for class_id, samples in class_samples.items():\n",
    "            center = samples.mean(dim=0)\n",
    "            spread = samples.std(dim=0).mean()  # Average std across dimensions\n",
    "            \n",
    "            class_centers[class_id] = center\n",
    "            class_spreads[class_id] = spread\n",
    "            \n",
    "            print(f\"  Class {class_id}: Center=({center[0]:.2f}, {center[1]:.2f}), Spread={spread:.2f}\")\n",
    "        \n",
    "        # Compute inter-class distances\n",
    "        print(\"\\nInter-class distances:\")\n",
    "        for i in range(config.num_classes):\n",
    "            for j in range(i+1, config.num_classes):\n",
    "                distance = torch.norm(class_centers[i] - class_centers[j]).item()\n",
    "                print(f\"  Class {i} ‚Üî Class {j}: {distance:.2f}\")\n",
    "        \n",
    "        return class_centers, class_spreads\n",
    "    \n",
    "    def test_class_consistency(self, num_runs: int = 3):\n",
    "        \"\"\"Test if the same class produces consistent samples across runs\"\"\"\n",
    "        print(\"=== Class Consistency Test ===\\n\")\n",
    "        \n",
    "        target_class = 0  # Test with class 0\n",
    "        samples_per_run = 10\n",
    "        all_runs = []\n",
    "        \n",
    "        for run in range(num_runs):\n",
    "            class_labels = torch.full((samples_per_run,), target_class, dtype=torch.long).to(device)\n",
    "            \n",
    "            try:\n",
    "                samples = self.sampler.sample_class_conditional(class_labels, num_steps=20)\n",
    "                if samples is not None:\n",
    "                    all_runs.append(samples)\n",
    "                    print(f\"Run {run+1}: Generated {len(samples)} samples\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Implement sampling methods first\")\n",
    "                    return\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error in run {run+1}: {e}\")\n",
    "                return\n",
    "        \n",
    "        # Analyze consistency across runs\n",
    "        run_centers = [samples.mean(dim=0) for samples in all_runs]\n",
    "        \n",
    "        print(f\"\\nConsistency analysis for class {target_class}:\")\n",
    "        for i, center in enumerate(run_centers):\n",
    "            print(f\"  Run {i+1} center: ({center[0]:.2f}, {center[1]:.2f})\")\n",
    "        \n",
    "        # Compute variance across runs\n",
    "        center_variance = torch.stack(run_centers).var(dim=0).mean().item()\n",
    "        print(f\"  Center variance across runs: {center_variance:.4f}\")\n",
    "        \n",
    "        if center_variance < 0.1:\n",
    "            print(\"‚úì Good consistency - similar centers across runs\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  High variance - class generation may be unstable\")\n",
    "\n",
    "# Test class-conditional analyzer (uncomment after implementing sampling methods)\n",
    "# analyzer = ClassConditionalAnalyzer(sampler)\n",
    "# analyzer.analyze_class_separation(samples_per_class=15)\n",
    "# analyzer.test_class_consistency(num_runs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bac4ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Classifier Guidance Implementation (25 minutes)\n",
    "\n",
    "### Task 4.1: Build Noise-Aware Classifier\n",
    "\n",
    "**Your Mission**: Implement a classifier that works on noisy data for classifier guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f89f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseAwareClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Classifier that can work on noisy data at different timesteps.\n",
    "    This is essential for classifier guidance during sampling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dim: int = 2, num_classes: int = 4, embed_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.data_dim = data_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Time embedding for noise level awareness\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "        \n",
    "        # Main classifier network\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(data_dim + embed_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Classify noisy data at timestep t\n",
    "        \n",
    "        Args:\n",
    "            x: Noisy data [batch_size, data_dim]\n",
    "            t: Timesteps [batch_size]\n",
    "            \n",
    "        Returns:\n",
    "            Class logits [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Handle timestep\n",
    "        if t.dim() == 0:\n",
    "            t = t.repeat(batch_size)\n",
    "        t_embed = self.time_mlp(t.float().unsqueeze(-1) / config.T)\n",
    "        \n",
    "        # Combine input with time embedding\n",
    "        x_with_time = torch.cat([x, t_embed], dim=-1)\n",
    "        logits = self.classifier(x_with_time)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class ClassifierTrainer:\n",
    "    \"\"\"\n",
    "    Training system for noise-aware classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, classifier: NoiseAwareClassifier, config: ConditionalConfig):\n",
    "        self.classifier = classifier\n",
    "        self.config = config\n",
    "        \n",
    "    def add_noise(self, x_start: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Add noise for classifier training on noisy data\"\"\"\n",
    "        noise = torch.randn_like(x_start)\n",
    "        alpha_cumprod_t = self.config.alphas_cumprod[t]\n",
    "        \n",
    "        if alpha_cumprod_t.dim() == 0:\n",
    "            alpha_cumprod_t = alpha_cumprod_t.unsqueeze(0)\n",
    "        if alpha_cumprod_t.shape[0] != x_start.shape[0]:\n",
    "            alpha_cumprod_t = alpha_cumprod_t.repeat(x_start.shape[0])\n",
    "        \n",
    "        alpha_cumprod_t = alpha_cumprod_t.view(-1, 1)\n",
    "        \n",
    "        x_noisy = torch.sqrt(alpha_cumprod_t) * x_start + torch.sqrt(1 - alpha_cumprod_t) * noise\n",
    "        return x_noisy\n",
    "    \n",
    "    def train_classifier(self, data: torch.Tensor, labels: torch.Tensor, \n",
    "                        epochs: int = 5, batch_size: int = 32, lr: float = 1e-3):\n",
    "        \"\"\"Train the noise-aware classifier\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.classifier.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.classifier.train()\n",
    "        \n",
    "        print(\"Training noise-aware classifier...\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_losses = []\n",
    "            n_batches = len(data) // batch_size\n",
    "            \n",
    "            for i in range(n_batches):\n",
    "                start_idx = i * batch_size\n",
    "                end_idx = min((i + 1) * batch_size, len(data))\n",
    "                \n",
    "                x_batch = data[start_idx:end_idx]\n",
    "                y_batch = labels[start_idx:end_idx]\n",
    "                \n",
    "                # Sample random timesteps\n",
    "                t_batch = torch.randint(0, self.config.T, (len(x_batch),)).to(device)\n",
    "                \n",
    "                # Add noise according to timestep\n",
    "                x_noisy = self.add_noise(x_batch, t_batch)\n",
    "                \n",
    "                # Classify noisy data\n",
    "                optimizer.zero_grad()\n",
    "                logits = self.classifier(x_noisy, t_batch)\n",
    "                loss = criterion(logits, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_losses.append(loss.item())\n",
    "            \n",
    "            avg_loss = np.mean(epoch_losses)\n",
    "            print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
    "        \n",
    "        self.classifier.eval()\n",
    "        print(\"‚úì Classifier training completed\")\n",
    "\n",
    "class ClassifierGuidanceSampler:\n",
    "    \"\"\"\n",
    "    Sampling system using classifier guidance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, unconditional_model: nn.Module, classifier: NoiseAwareClassifier, \n",
    "                 config: ConditionalConfig):\n",
    "        self.unconditional_model = unconditional_model\n",
    "        self.classifier = classifier\n",
    "        self.config = config\n",
    "        \n",
    "        self.unconditional_model.eval()\n",
    "        self.classifier.eval()\n",
    "    \n",
    "    def compute_classifier_gradient(self, x_t: torch.Tensor, target_class: int, t: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        TODO: Implement classifier gradient computation\n",
    "        \n",
    "        Compute ‚àá_x log p(y|x_t) for classifier guidance.\n",
    "        \n",
    "        Steps:\n",
    "        1. Enable gradients for x_t\n",
    "        2. Get classifier logits for x_t at timestep t\n",
    "        3. Compute log probability for target class\n",
    "        4. Compute gradient with respect to x_t\n",
    "        5. Return the gradient\n",
    "        \n",
    "        Args:\n",
    "            x_t: Current noisy state [batch_size, data_dim]\n",
    "            target_class: Target class for guidance\n",
    "            t: Current timestep\n",
    "            \n",
    "        Returns:\n",
    "            Classifier gradient [batch_size, data_dim]\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        # Hint: Use x_t.requires_grad_(True) and torch.autograd.grad()\n",
    "        # Remember to handle the log probability correctly\n",
    "        pass\n",
    "    \n",
    "    def classifier_guided_step(self, x_t: torch.Tensor, target_class: int, t: int, s: int, \n",
    "                             guidance_scale: float = 1.0) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        TODO: Implement classifier-guided sampling step\n",
    "        \n",
    "        Apply classifier guidance to modify the noise prediction:\n",
    "        ŒµÃÉ = Œµ_Œ∏(x_t, t) - œâ‚àö(1-·æ±_t) ‚àá_x log p(y|x_t)\n",
    "        \n",
    "        Steps:\n",
    "        1. Get unconditional noise prediction\n",
    "        2. Compute classifier gradient\n",
    "        3. Apply guidance: modify noise prediction using gradient\n",
    "        4. Use modified noise for DDIM update\n",
    "        5. Return updated state\n",
    "        \n",
    "        Args:\n",
    "            x_t: Current noisy state\n",
    "            target_class: Target class for guidance\n",
    "            t: Current timestep\n",
    "            s: Target timestep (s < t)\n",
    "            guidance_scale: Strength of classifier guidance (œâ)\n",
    "            \n",
    "        Returns:\n",
    "            x_s: Updated state with classifier guidance\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        # Hint: Combine unconditional prediction with classifier gradient\n",
    "        # Use DDIM update formula from previous labs\n",
    "        pass\n",
    "    \n",
    "    def sample_with_classifier_guidance(self, target_class: int, num_samples: int = 10, \n",
    "                                      num_steps: int = 20, guidance_scale: float = 2.0) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        TODO: Implement complete classifier-guided sampling\n",
    "        \n",
    "        Generate samples using classifier guidance.\n",
    "        \n",
    "        Steps:\n",
    "        1. Create timestep schedule\n",
    "        2. Initialize x_T from pure noise\n",
    "        3. For each timestep pair: apply classifier_guided_step\n",
    "        4. Return final samples\n",
    "        \n",
    "        Args:\n",
    "            target_class: Class to generate\n",
    "            num_samples: Number of samples to generate\n",
    "            num_steps: Number of sampling steps\n",
    "            guidance_scale: Strength of guidance\n",
    "            \n",
    "        Returns:\n",
    "            Generated samples [num_samples, data_dim]\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        # Hint: Similar to class-conditional sampling but use classifier_guided_step\n",
    "        pass\n",
    "    \n",
    "    def create_timestep_schedule(self, num_steps: int) -> List[int]:\n",
    "        \"\"\"Create uniform timestep schedule\"\"\"\n",
    "        step_size = self.config.T // num_steps\n",
    "        timesteps = list(range(self.config.T - 1, -1, -step_size))\n",
    "        timesteps.append(0)\n",
    "        return timesteps[:num_steps + 1]\n",
    "    \n",
    "    def demonstrate_classifier_guidance(self, guidance_scales: List[float] = [0.0, 1.0, 2.0, 5.0]):\n",
    "        \"\"\"Demonstrate classifier guidance with different scales\"\"\"\n",
    "        print(\"=== Classifier Guidance Demonstration ===\\n\")\n",
    "        \n",
    "        target_class = 0  # Generate circles\n",
    "        samples_per_scale = 15\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for scale in guidance_scales:\n",
    "            print(f\"Testing guidance scale œâ = {scale}\")\n",
    "            \n",
    "            try:\n",
    "                samples = self.sample_with_classifier_guidance(\n",
    "                    target_class=target_class,\n",
    "                    num_samples=samples_per_scale,\n",
    "                    num_steps=20,\n",
    "                    guidance_scale=scale\n",
    "                )\n",
    "                \n",
    "                if samples is not None:\n",
    "                    results[scale] = samples\n",
    "                    print(f\"  ‚úì Generated {len(samples)} samples\")\n",
    "                else:\n",
    "                    print(f\"  ‚ùå Implement classifier guidance methods first\")\n",
    "                    return\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error with scale {scale}: {e}\")\n",
    "                return\n",
    "        \n",
    "        if results:\n",
    "            self.visualize_guidance_effects(results, target_class)\n",
    "    \n",
    "    def visualize_guidance_effects(self, results: Dict[float, torch.Tensor], target_class: int):\n",
    "        \"\"\"Visualize the effect of different guidance scales\"\"\"\n",
    "        n_scales = len(results)\n",
    "        fig, axes = plt.subplots(1, n_scales, figsize=(4*n_scales, 4))\n",
    "        \n",
    "        if n_scales == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        colors = ['red', 'blue', 'green', 'orange']\n",
    "        class_names = ['Circle', 'Square', 'Triangle', 'Line']\n",
    "        \n",
    "        for i, (scale, samples) in enumerate(results.items()):\n",
    "            # Plot generated samples\n",
    "            axes[i].scatter(samples[:, 0].cpu(), samples[:, 1].cpu(), \n",
    "                           c=colors[target_class], alpha=0.7, s=50, \n",
    "                           label=f'Generated {class_names[target_class]}')\n",
    "            \n",
    "            # Plot reference data for comparison\n",
    "            class_mask = train_labels == target_class\n",
    "            ref_data = train_data[class_mask]\n",
    "            axes[i].scatter(ref_data[:, 0].cpu(), ref_data[:, 1].cpu(), \n",
    "                           c='gray', alpha=0.3, s=20, label='Reference')\n",
    "            \n",
    "            axes[i].set_title(f'Guidance Scale œâ = {scale}')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            axes[i].axis('equal')\n",
    "        \n",
    "        plt.suptitle(f'Classifier Guidance Effect on {class_names[target_class]} Generation')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create unconditional model for classifier guidance\n",
    "class SimpleUnconditionalDiffusion(nn.Module):\n",
    "    \"\"\"Simple unconditional model for classifier guidance demo\"\"\"\n",
    "    def __init__(self, data_dim: int = 2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(data_dim + 64, 128),  # data + time embedding\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, data_dim)\n",
    "        )\n",
    "        \n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        if t.dim() == 0:\n",
    "            t = t.repeat(x.shape[0])\n",
    "        t_embed = self.time_mlp(t.float().unsqueeze(-1) / config.T)\n",
    "        return self.net(torch.cat([x, t_embed], dim=-1))\n",
    "\n",
    "# Create and train noise-aware classifier\n",
    "print(\"Creating noise-aware classifier...\")\n",
    "noise_aware_classifier = NoiseAwareClassifier(data_dim=2, num_classes=config.num_classes).to(device)\n",
    "\n",
    "classifier_trainer = ClassifierTrainer(noise_aware_classifier, config)\n",
    "classifier_trainer.train_classifier(train_data, train_labels, epochs=3, batch_size=16)\n",
    "\n",
    "# Create unconditional model and classifier guidance sampler\n",
    "unconditional_model = SimpleUnconditionalDiffusion().to(device)\n",
    "guidance_sampler = ClassifierGuidanceSampler(unconditional_model, noise_aware_classifier, config)\n",
    "\n",
    "# Demonstrate classifier guidance (uncomment after implementing TODOs)\n",
    "# guidance_sampler.demonstrate_classifier_guidance([0.0, 1.0, 2.0, 4.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12cf9b7",
   "metadata": {},
   "source": [
    "### Task 4.2: Analyze Classifier Guidance Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierGuidanceAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze the performance characteristics of classifier guidance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, guidance_sampler: ClassifierGuidanceSampler):\n",
    "        self.guidance_sampler = guidance_sampler\n",
    "        \n",
    "    def analyze_guidance_strength(self, target_class: int = 0):\n",
    "        \"\"\"Analyze how guidance strength affects generation quality and diversity\"\"\"\n",
    "        print(\"=== Guidance Strength Analysis ===\\n\")\n",
    "        \n",
    "        guidance_scales = [0.0, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "        samples_per_scale = 20\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for scale in guidance_scales:\n",
    "            print(f\"Testing guidance scale {scale}...\")\n",
    "            \n",
    "            try:\n",
    "                samples = self.guidance_sampler.sample_with_classifier_guidance(\n",
    "                    target_class=target_class,\n",
    "                    num_samples=samples_per_scale,\n",
    "                    num_steps=20,\n",
    "                    guidance_scale=scale\n",
    "                )\n",
    "                \n",
    "                if samples is not None:\n",
    "                    # Compute quality metrics\n",
    "                    center = samples.mean(dim=0)\n",
    "                    spread = samples.std(dim=0).mean().item()\n",
    "                    \n",
    "                    results[scale] = {\n",
    "                        'samples': samples,\n",
    "                        'center': center,\n",
    "                        'spread': spread\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"  Center: ({center[0]:.2f}, {center[1]:.2f}), Spread: {spread:.3f}\")\n",
    "                else:\n",
    "                    print(\"  ‚ùå Implement guidance methods first\")\n",
    "                    return\n",
    "            except Exception as e:\n",
    "                print(f\"  Error with scale {scale}: {e}\")\n",
    "                return\n",
    "        \n",
    "        if results:\n",
    "            self.plot_guidance_analysis(results, target_class)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_guidance_analysis(self, results: Dict, target_class: int):\n",
    "        \"\"\"Plot guidance strength analysis results\"\"\"\n",
    "        scales = list(results.keys())\n",
    "        spreads = [results[s]['spread'] for s in scales]\n",
    "        \n",
    "        # Plot spread vs guidance scale\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(scales, spreads, 'bo-', linewidth=2, markersize=8)\n",
    "        plt.xlabel('Guidance Scale œâ')\n",
    "        plt.ylabel('Sample Spread (Diversity)')\n",
    "        plt.title('Diversity vs Guidance Strength')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot sample evolution\n",
    "        plt.subplot(1, 2, 2)\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(scales)))\n",
    "        \n",
    "        for i, (scale, result) in enumerate(results.items()):\n",
    "            samples = result['samples']\n",
    "            plt.scatter(samples[:, 0].cpu(), samples[:, 1].cpu(), \n",
    "                       c=[colors[i]], alpha=0.6, s=30, label=f'œâ={scale}')\n",
    "        \n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.title('Sample Distribution vs Guidance')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axis('equal')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nKey Insights:\")\n",
    "        print(\"‚Ä¢ Higher guidance ‚Üí Lower diversity (more focused)\")\n",
    "        print(\"‚Ä¢ œâ=0: Unconditional generation (high diversity)\")\n",
    "        print(\"‚Ä¢ œâ>5: Risk of mode collapse or artifacts\")\n",
    "        print(\"‚Ä¢ Optimal œâ depends on application needs\")\n",
    "    \n",
    "    def compare_with_class_conditional(self, target_class: int = 0):\n",
    "        \"\"\"Compare classifier guidance with class-conditional generation\"\"\"\n",
    "        print(\"=== Classifier vs Class-Conditional Comparison ===\\n\")\n",
    "        \n",
    "        samples_per_method = 25\n",
    "        \n",
    "        try:\n",
    "            # Classifier guidance samples\n",
    "            guidance_samples = self.guidance_sampler.sample_with_classifier_guidance(\n",
    "                target_class=target_class,\n",
    "                num_samples=samples_per_method,\n",
    "                num_steps=20,\n",
    "                guidance_scale=2.0\n",
    "            )\n",
    "            \n",
    "            if guidance_samples is None:\n",
    "                print(\"‚ùå Implement classifier guidance methods first\")\n",
    "                return\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error with classifier guidance: {e}\")\n",
    "            return\n",
    "        \n",
    "        # Note: This would compare with class-conditional if implemented\n",
    "        print(\"Classifier guidance samples generated successfully\")\n",
    "        print(\"(To compare with class-conditional, implement Part 3 methods)\")\n",
    "        \n",
    "        return guidance_samples\n",
    "\n",
    "# Test classifier guidance analyzer (uncomment after implementing guidance methods)\n",
    "# guidance_analyzer = ClassifierGuidanceAnalyzer(guidance_sampler)\n",
    "# guidance_results = guidance_analyzer.analyze_guidance_strength(target_class=0)\n",
    "# guidance_analyzer.compare_with_class_conditional(target_class=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8722945",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Classifier-Free Guidance Implementation (20 minutes)\n",
    "\n",
    "### Task 5.1: Implement CFG Training and Sampling\n",
    "\n",
    "**Your Mission**: Build the modern standard for conditional generation - classifier-free guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be128571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierFreeUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net that supports both conditional and unconditional generation.\n",
    "    This is the key to classifier-free guidance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dim: int = 2, num_classes: int = 4, embed_dim: int = 64):\n",
    "        super().__init__()\n",
    "        self.data_dim = data_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Class embedding table (with null token for unconditional)\n",
    "        self.class_embedding = nn.Embedding(num_classes + 1, embed_dim)  # +1 for null token\n",
    "        self.null_token = num_classes  # Use last index as null token\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(1, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "        \n",
    "        # Main network\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(data_dim + embed_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128 + embed_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, data_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, class_labels: Optional[torch.Tensor], t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass supporting both conditional and unconditional generation\n",
    "        \n",
    "        Args:\n",
    "            x: Noisy data [batch_size, data_dim]\n",
    "            class_labels: Class labels [batch_size] or None for unconditional\n",
    "            t: Timesteps [batch_size]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Handle timestep\n",
    "        if t.dim() == 0:\n",
    "            t = t.repeat(batch_size)\n",
    "        t_embed = self.time_mlp(t.float().unsqueeze(-1) / config.T)\n",
    "        \n",
    "        # Handle class conditioning\n",
    "        if class_labels is not None:\n",
    "            class_embed = self.class_embedding(class_labels)\n",
    "        else:\n",
    "            # Use null token for unconditional\n",
    "            null_labels = torch.full((batch_size,), self.null_token, dtype=torch.long).to(device)\n",
    "            class_embed = self.class_embedding(null_labels)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined_embed = t_embed + class_embed\n",
    "        \n",
    "        # Forward pass\n",
    "        x_with_embed = torch.cat([x, combined_embed], dim=-1)\n",
    "        encoded = self.encoder(x_with_embed)\n",
    "        decoder_input = torch.cat([encoded, combined_embed], dim=-1)\n",
    "        output = self.decoder(decoder_input)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class CFGTrainer:\n",
    "    \"\"\"\n",
    "    Training system for classifier-free guidance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: ClassifierFreeUNet, config: ConditionalConfig):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.model.train()\n",
    "        \n",
    "    def add_noise(self, x_start: torch.Tensor, t: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Add noise according to forward process\"\"\"\n",
    "        noise = torch.randn_like(x_start)\n",
    "        alpha_cumprod_t = self.config.alphas_cumprod[t]\n",
    "        \n",
    "        if alpha_cumprod_t.dim() == 0:\n",
    "            alpha_cumprod_t = alpha_cumprod_t.unsqueeze(0)\n",
    "        if alpha_cumprod_t.shape[0] != x_start.shape[0]:\n",
    "            alpha_cumprod_t = alpha_cumprod_t.repeat(x_start.shape[0])\n",
    "        \n",
    "        alpha_cumprod_t = alpha_cumprod_t.view(-1, 1)\n",
    "        \n",
    "        x_noisy = torch.sqrt(alpha_cumprod_t) * x_start + torch.sqrt(1 - alpha_cumprod_t) * noise\n",
    "        return x_noisy, noise\n",
    "    \n",
    "    def cfg_training_step(self, x_batch: torch.Tensor, class_batch: torch.Tensor) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        TODO: Implement classifier-free guidance training step\n",
    "        \n",
    "        The key insight: train one model to do both conditional and unconditional generation\n",
    "        by randomly dropping the class condition during training.\n",
    "        \n",
    "        Steps:\n",
    "        1. Sample random timesteps for each item in batch\n",
    "        2. Sample noise and create noisy data\n",
    "        3. Apply conditioning dropout: randomly set some class_labels to None\n",
    "        4. Predict noise using model (handles both conditional and unconditional)\n",
    "        5. Compute MSE loss between predicted and actual noise\n",
    "        6. Return loss and metrics\n",
    "        \n",
    "        Args:\n",
    "            x_batch: Clean data [batch_size, data_dim]  \n",
    "            class_batch: Class labels [batch_size]\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with loss and metrics\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        # Hint: Use random dropout with probability config.dropout_prob\n",
    "        # When dropping condition, pass None as class_labels to model\n",
    "        pass\n",
    "    \n",
    "    def train_cfg_epoch(self, data: torch.Tensor, labels: torch.Tensor, \n",
    "                       batch_size: int = 32, lr: float = 1e-3) -> List[float]:\n",
    "        \"\"\"Train one epoch with CFG objective\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        losses = []\n",
    "        \n",
    "        n_batches = len(data) // batch_size\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, len(data))\n",
    "            \n",
    "            x_batch = data[start_idx:end_idx]\n",
    "            class_batch = labels[start_idx:end_idx]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            try:\n",
    "                result = self.cfg_training_step(x_batch, class_batch)\n",
    "                if result and 'loss' in result:\n",
    "                    loss = result['loss']\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    losses.append(loss.item())\n",
    "                else:\n",
    "                    print(f\"Batch {i}: Implement cfg_training_step() method\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Batch {i}: Error in CFG training - {e}\")\n",
    "                break\n",
    "        \n",
    "        return losses\n",
    "\n",
    "class CFGSampler:\n",
    "    \"\"\"\n",
    "    Sampling system using classifier-free guidance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: ClassifierFreeUNet, config: ConditionalConfig):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.model.eval()\n",
    "    \n",
    "    def cfg_step(self, x_t: torch.Tensor, class_labels: torch.Tensor, t: int, s: int, \n",
    "                 guidance_scale: float = 1.0) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        TODO: Implement classifier-free guidance sampling step\n",
    "        \n",
    "        The CFG magic: ŒµÃÉ = (1+œâ)Œµ_cond - œâŒµ_uncond\n",
    "        \n",
    "        Steps:\n",
    "        1. Get conditional noise prediction: Œµ_cond = model(x_t, class_labels, t)\n",
    "        2. Get unconditional noise prediction: Œµ_uncond = model(x_t, None, t)  \n",
    "        3. Apply CFG formula: ŒµÃÉ = (1+œâ)Œµ_cond - œâŒµ_uncond\n",
    "        4. Use guided noise prediction for DDIM update\n",
    "        5. Return updated state\n",
    "        \n",
    "        Args:\n",
    "            x_t: Current noisy state [batch_size, data_dim]\n",
    "            class_labels: Target class labels [batch_size]\n",
    "            t: Current timestep\n",
    "            s: Target timestep (s < t)\n",
    "            guidance_scale: CFG guidance scale (œâ)\n",
    "            \n",
    "        Returns:\n",
    "            x_s: Updated state with CFG guidance\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        # Hint: Call model twice - once with class_labels, once with None\n",
    "        # Apply CFG formula and then use DDIM update\n",
    "        pass\n",
    "    \n",
    "    def sample_cfg(self, class_labels: torch.Tensor, num_steps: int = 20, \n",
    "                   guidance_scale: float = 2.0) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        TODO: Implement complete CFG sampling\n",
    "        \n",
    "        Generate samples using classifier-free guidance.\n",
    "        \n",
    "        Steps:\n",
    "        1. Create timestep schedule\n",
    "        2. Initialize x_T from pure noise\n",
    "        3. For each timestep pair: apply cfg_step\n",
    "        4. Return final samples\n",
    "        \n",
    "        Args:\n",
    "            class_labels: Target class labels [batch_size]\n",
    "            num_steps: Number of sampling steps\n",
    "            guidance_scale: CFG guidance scale\n",
    "            \n",
    "        Returns:\n",
    "            Generated samples [batch_size, data_dim]\n",
    "        \"\"\"\n",
    "        # TODO: Your implementation here\n",
    "        # Hint: Similar to previous samplers but use cfg_step\n",
    "        pass\n",
    "    \n",
    "    def create_timestep_schedule(self, num_steps: int) -> List[int]:\n",
    "        \"\"\"Create uniform timestep schedule\"\"\"\n",
    "        step_size = self.config.T // num_steps\n",
    "        timesteps = list(range(self.config.T - 1, -1, -step_size))\n",
    "        timesteps.append(0)\n",
    "        return timesteps[:num_steps + 1]\n",
    "    \n",
    "    def demonstrate_cfg_generation(self, guidance_scales: List[float] = [0.0, 1.0, 2.0, 5.0]):\n",
    "        \"\"\"Demonstrate CFG with different guidance scales\"\"\"\n",
    "        print(\"=== Classifier-Free Guidance Demonstration ===\\n\")\n",
    "        \n",
    "        target_class = 0\n",
    "        samples_per_scale = 15\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for scale in guidance_scales:\n",
    "            print(f\"Testing CFG scale œâ = {scale}\")\n",
    "            \n",
    "            class_labels = torch.full((samples_per_scale,), target_class, dtype=torch.long).to(device)\n",
    "            \n",
    "            try:\n",
    "                samples = self.sample_cfg(class_labels, num_steps=20, guidance_scale=scale)\n",
    "                \n",
    "                if samples is not None:\n",
    "                    results[scale] = samples\n",
    "                    print(f\"  ‚úì Generated {len(samples)} samples\")\n",
    "                else:\n",
    "                    print(f\"  ‚ùå Implement CFG sampling methods first\")\n",
    "                    return\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error with scale {scale}: {e}\")\n",
    "                return\n",
    "        \n",
    "        if results:\n",
    "            self.visualize_cfg_effects(results, target_class)\n",
    "    \n",
    "    def visualize_cfg_effects(self, results: Dict[float, torch.Tensor], target_class: int):\n",
    "        \"\"\"Visualize CFG effects across different scales\"\"\"\n",
    "        n_scales = len(results)\n",
    "        fig, axes = plt.subplots(1, n_scales, figsize=(4*n_scales, 4))\n",
    "        \n",
    "        if n_scales == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        colors = ['red', 'blue', 'green', 'orange']\n",
    "        class_names = ['Circle', 'Square', 'Triangle', 'Line']\n",
    "        \n",
    "        for i, (scale, samples) in enumerate(results.items()):\n",
    "            # Plot generated samples\n",
    "            axes[i].scatter(samples[:, 0].cpu(), samples[:, 1].cpu(), \n",
    "                           c=colors[target_class], alpha=0.7, s=50)\n",
    "            \n",
    "            # Plot reference data\n",
    "            class_mask = train_labels == target_class\n",
    "            ref_data = train_data[class_mask]\n",
    "            axes[i].scatter(ref_data[:, 0].cpu(), ref_data[:, 1].cpu(), \n",
    "                           c='gray', alpha=0.3, s=20, label='Reference')\n",
    "            \n",
    "            # Determine behavior\n",
    "            if scale == 0.0:\n",
    "                behavior = \"Unconditional\"\n",
    "            elif scale < 2.0:\n",
    "                behavior = \"Weak Guidance\"\n",
    "            elif scale < 5.0:\n",
    "                behavior = \"Strong Guidance\"\n",
    "            else:\n",
    "                behavior = \"Very Strong\"\n",
    "            \n",
    "            axes[i].set_title(f'CFG œâ = {scale}\\n{behavior}')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            axes[i].axis('equal')\n",
    "        \n",
    "        plt.suptitle(f'Classifier-Free Guidance: {class_names[target_class]} Generation')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create and train CFG model\n",
    "print(\"Creating classifier-free guidance model...\")\n",
    "cfg_model = ClassifierFreeUNet(data_dim=2, num_classes=config.num_classes).to(device)\n",
    "\n",
    "# Test CFG training\n",
    "cfg_trainer = CFGTrainer(cfg_model, config)\n",
    "\n",
    "print(\"\\nCFG training demonstration...\")\n",
    "cfg_losses = cfg_trainer.train_cfg_epoch(train_data, train_labels, batch_size=16, lr=1e-3)\n",
    "if cfg_losses:\n",
    "    print(f\"CFG training losses: {cfg_losses[:5]}...\")\n",
    "    \n",
    "    # Test CFG sampling\n",
    "    cfg_sampler = CFGSampler(cfg_model, config)\n",
    "    cfg_sampler.demonstrate_cfg_generation([0.0, 1.0, 2.0, 4.0])\n",
    "else:\n",
    "    print(\"‚ùå Implement cfg_training_step() to proceed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0717afe",
   "metadata": {},
   "source": [
    "### Task 5.2: CFG vs Other Methods Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeddb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehensiveConditionalComparison:\n",
    "    \"\"\"\n",
    "    Compare all three conditional generation approaches:\n",
    "    1. Class-conditional\n",
    "    2. Classifier guidance  \n",
    "    3. Classifier-free guidance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, class_conditional_sampler: ClassConditionalSampler,\n",
    "                 classifier_guidance_sampler: ClassifierGuidanceSampler,\n",
    "                 cfg_sampler: CFGSampler):\n",
    "        self.class_conditional = class_conditional_sampler\n",
    "        self.classifier_guidance = classifier_guidance_sampler\n",
    "        self.cfg = cfg_sampler\n",
    "    \n",
    "    def compare_all_methods(self, target_class: int = 0, samples_per_method: int = 20):\n",
    "        \"\"\"Compare all three conditioning approaches\"\"\"\n",
    "        print(\"=== Comprehensive Conditional Generation Comparison ===\\n\")\n",
    "        \n",
    "        results = {}\n",
    "        timings = {}\n",
    "        \n",
    "        # Test class-conditional\n",
    "        print(\"1. Testing Class-Conditional...\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            class_labels = torch.full((samples_per_method,), target_class, dtype=torch.long).to(device)\n",
    "            cc_samples = self.class_conditional.sample_class_conditional(class_labels, num_steps=20)\n",
    "            cc_time = time.time() - start_time\n",
    "            \n",
    "            if cc_samples is not None:\n",
    "                results['Class-Conditional'] = cc_samples\n",
    "                timings['Class-Conditional'] = cc_time\n",
    "                print(f\"   ‚úì Generated in {cc_time:.3f}s\")\n",
    "            else:\n",
    "                print(\"   ‚ùå Class-conditional not implemented\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Class-conditional error: {e}\")\n",
    "        \n",
    "        # Test classifier guidance\n",
    "        print(\"2. Testing Classifier Guidance...\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            cg_samples = self.classifier_guidance.sample_with_classifier_guidance(\n",
    "                target_class=target_class, num_samples=samples_per_method, \n",
    "                num_steps=20, guidance_scale=2.0)\n",
    "            cg_time = time.time() - start_time\n",
    "            \n",
    "            if cg_samples is not None:\n",
    "                results['Classifier Guidance'] = cg_samples\n",
    "                timings['Classifier Guidance'] = cg_time\n",
    "                print(f\"   ‚úì Generated in {cg_time:.3f}s\")\n",
    "            else:\n",
    "                print(\"   ‚ùå Classifier guidance not implemented\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Classifier guidance error: {e}\")\n",
    "        \n",
    "        # Test CFG\n",
    "        print(\"3. Testing Classifier-Free Guidance...\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            class_labels = torch.full((samples_per_method,), target_class, dtype=torch.long).to(device)\n",
    "            cfg_samples = self.cfg.sample_cfg(class_labels, num_steps=20, guidance_scale=2.0)\n",
    "            cfg_time = time.time() - start_time\n",
    "            \n",
    "            if cfg_samples is not None:\n",
    "                results['CFG'] = cfg_samples\n",
    "                timings['CFG'] = cfg_time\n",
    "                print(f\"   ‚úì Generated in {cfg_time:.3f}s\")\n",
    "            else:\n",
    "                print(\"   ‚ùå CFG not implemented\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå CFG error: {e}\")\n",
    "        \n",
    "        if results:\n",
    "            self.visualize_method_comparison(results, target_class)\n",
    "            self.analyze_method_characteristics(results, timings)\n",
    "        \n",
    "        return results, timings\n",
    "    \n",
    "    def visualize_method_comparison(self, results: Dict[str, torch.Tensor], target_class: int):\n",
    "        \"\"\"Visualize comparison between methods\"\"\"\n",
    "        n_methods = len(results)\n",
    "        fig, axes = plt.subplots(1, n_methods + 1, figsize=(4*(n_methods+1), 4))\n",
    "        \n",
    "        colors = ['red', 'blue', 'green', 'orange']\n",
    "        class_names = ['Circle', 'Square', 'Triangle', 'Line']\n",
    "        \n",
    "        # Reference data\n",
    "        class_mask = train_labels == target_class\n",
    "        ref_data = train_data[class_mask]\n",
    "        axes[0].scatter(ref_data[:, 0].cpu(), ref_data[:, 1].cpu(), \n",
    "                       c=colors[target_class], alpha=0.7, s=50)\n",
    "        axes[0].set_title('Reference\\nTraining Data')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        axes[0].axis('equal')\n",
    "        \n",
    "        # Generated samples from each method\n",
    "        for i, (method, samples) in enumerate(results.items()):\n",
    "            axes[i+1].scatter(samples[:, 0].cpu(), samples[:, 1].cpu(), \n",
    "                             c=colors[target_class], alpha=0.7, s=50)\n",
    "            axes[i+1].scatter(ref_data[:, 0].cpu(), ref_data[:, 1].cpu(), \n",
    "                             c='gray', alpha=0.2, s=10)\n",
    "            axes[i+1].set_title(f'{method}\\nGeneration')\n",
    "            axes[i+1].grid(True, alpha=0.3)\n",
    "            axes[i+1].axis('equal')\n",
    "        \n",
    "        plt.suptitle(f'Conditional Generation Methods: {class_names[target_class]}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def analyze_method_characteristics(self, results: Dict[str, torch.Tensor], \n",
    "                                     timings: Dict[str, float]):\n",
    "        \"\"\"Analyze characteristics of each method\"\"\"\n",
    "        print(\"\\n=== Method Analysis ===\\n\")\n",
    "        \n",
    "        characteristics = {}\n",
    "        \n",
    "        for method, samples in results.items():\n",
    "            # Compute basic statistics\n",
    "            center = samples.mean(dim=0)\n",
    "            spread = samples.std(dim=0).mean().item()\n",
    "            \n",
    "            characteristics[method] = {\n",
    "                'center': center,\n",
    "                'spread': spread,\n",
    "                'time': timings.get(method, 0)\n",
    "            }\n",
    "            \n",
    "            print(f\"{method}:\")\n",
    "            print(f\"  Center: ({center[0]:.2f}, {center[1]:.2f})\")\n",
    "            print(f\"  Spread: {spread:.3f}\")\n",
    "            print(f\"  Time: {timings.get(method, 0):.3f}s\")\n",
    "            print()\n",
    "        \n",
    "        # Create comparison chart\n",
    "        self.plot_method_comparison_chart(characteristics)\n",
    "        \n",
    "        return characteristics\n",
    "    \n",
    "    def plot_method_comparison_chart(self, characteristics: Dict):\n",
    "        \"\"\"Plot comparison chart of method characteristics\"\"\"\n",
    "        methods = list(characteristics.keys())\n",
    "        spreads = [characteristics[m]['spread'] for m in methods]\n",
    "        times = [characteristics[m]['time'] for m in methods]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Diversity comparison\n",
    "        bars1 = ax1.bar(methods, spreads, color=['lightblue', 'lightcoral', 'lightgreen'])\n",
    "        ax1.set_ylabel('Sample Spread (Diversity)')\n",
    "        ax1.set_title('Generation Diversity')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        for bar, spread in zip(bars1, spreads):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "                    f'{spread:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Speed comparison\n",
    "        bars2 = ax2.bar(methods, times, color=['lightblue', 'lightcoral', 'lightgreen'])\n",
    "        ax2.set_ylabel('Generation Time (s)')\n",
    "        ax2.set_title('Generation Speed')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        for bar, time_val in zip(bars2, times):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "                    f'{time_val:.3f}s', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def summarize_trade_offs(self):\n",
    "        \"\"\"Summarize the trade-offs between methods\"\"\"\n",
    "        print(\"=== Method Trade-offs Summary ===\\n\")\n",
    "        \n",
    "        trade_offs = {\n",
    "            \"Class-Conditional\": {\n",
    "                \"Pros\": [\"‚úì Simple implementation\", \"‚úì Fast sampling\", \"‚úì Reliable results\", \"‚úì Memory efficient\"],\n",
    "                \"Cons\": [\"‚ùå Fixed classes only\", \"‚ùå Limited flexibility\", \"‚ùå Requires retraining for new classes\"],\n",
    "                \"Best for\": \"Simple applications with fixed, known classes\"\n",
    "            },\n",
    "            \"Classifier Guidance\": {\n",
    "                \"Pros\": [\"‚úì Works with any pretrained model\", \"‚úì Modular approach\", \"‚úì Strong control\"],\n",
    "                \"Cons\": [\"‚ùå Requires separate classifier\", \"‚ùå Slower (extra gradients)\", \"‚ùå Complex implementation\"],\n",
    "                \"Best for\": \"Research and experimentation with existing models\"\n",
    "            },\n",
    "            \"Classifier-Free Guidance\": {\n",
    "                \"Pros\": [\"‚úì No separate classifier\", \"‚úì Modern standard\", \"‚úì Excellent text conditioning\", \"‚úì Flexible control\"],\n",
    "                \"Cons\": [\"‚ùå Requires retraining\", \"‚ùå 2x forward passes\", \"‚ùå More complex training\"],\n",
    "                \"Best for\": \"Production systems, text-to-image, modern applications\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for method, info in trade_offs.items():\n",
    "            print(f\"üîπ {method}:\")\n",
    "            print(f\"   Pros: {', '.join(info['Pros'])}\")\n",
    "            print(f\"   Cons: {', '.join(info['Cons'])}\")\n",
    "            print(f\"   Best for: {info['Best for']}\")\n",
    "            print()\n",
    "        \n",
    "        print(\"üèÜ Winner for modern applications: Classifier-Free Guidance\")\n",
    "        print(\"   ‚Ä¢ Powers Stable Diffusion, DALL-E, Midjourney\")\n",
    "        print(\"   ‚Ä¢ Best balance of quality, flexibility, and practicality\")\n",
    "\n",
    "# Create comprehensive comparison (uncomment after implementing all methods)\n",
    "# Note: This will only work if all three methods are implemented\n",
    "try:\n",
    "    if 'sampler' in locals() and 'guidance_sampler' in locals() and 'cfg_sampler' in locals():\n",
    "        comprehensive_comparison = ComprehensiveConditionalComparison(\n",
    "            sampler, guidance_sampler, cfg_sampler)\n",
    "        \n",
    "        comparison_results, comparison_timings = comprehensive_comparison.compare_all_methods(\n",
    "            target_class=0, samples_per_method=15)\n",
    "        \n",
    "        comprehensive_comparison.summarize_trade_offs()\n",
    "    else:\n",
    "        print(\"Implement all three methods to run comprehensive comparison\")\n",
    "except:\n",
    "    print(\"Implement all three sampling methods to run comprehensive comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c9c6b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Advanced Conditioning and Real-World Applications (10 minutes)\n",
    "\n",
    "### Task 6.1: Multi-Scale Conditioning and Modern Techniques\n",
    "\n",
    "**Your Mission**: Explore advanced conditioning techniques used in production systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb4397",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedConditioningDemo:\n",
    "    \"\"\"\n",
    "    Demonstrate advanced conditioning techniques used in modern diffusion models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg_model: ClassifierFreeUNet, config: ConditionalConfig):\n",
    "        self.model = cfg_model\n",
    "        self.config = config\n",
    "        \n",
    "    def demonstrate_guidance_interpolation(self, class_a: int = 0, class_b: int = 1, \n",
    "                                         num_interpolation_steps: int = 5):\n",
    "        \"\"\"Demonstrate interpolation between different class conditions\"\"\"\n",
    "        print(\"=== Guidance Interpolation Demo ===\\n\")\n",
    "        \n",
    "        # This would require more sophisticated implementation\n",
    "        # For now, we'll demonstrate the concept\n",
    "        \n",
    "        print(f\"Interpolating between class {class_a} and class {class_b}\")\n",
    "        print(\"In advanced systems, this enables:\")\n",
    "        print(\"‚Ä¢ Smooth transitions between conditions\")\n",
    "        print(\"‚Ä¢ Creative control over generation\")\n",
    "        print(\"‚Ä¢ Morphing between different styles/classes\")\n",
    "        \n",
    "        # Simulate interpolation visualization\n",
    "        fig, axes = plt.subplots(1, num_interpolation_steps, figsize=(3*num_interpolation_steps, 3))\n",
    "        \n",
    "        colors = ['red', 'blue', 'green', 'orange']\n",
    "        class_names = ['Circle', 'Square', 'Triangle', 'Line']\n",
    "        \n",
    "        for i in range(num_interpolation_steps):\n",
    "            # Interpolation weight\n",
    "            weight = i / (num_interpolation_steps - 1)\n",
    "            \n",
    "            # Simulate interpolated samples (in real implementation, you'd blend class embeddings)\n",
    "            if i < num_interpolation_steps // 2:\n",
    "                color = colors[class_a]\n",
    "                title = f'{class_names[class_a]}\\n({1-weight:.1f})'\n",
    "            else:\n",
    "                color = colors[class_b] \n",
    "                title = f'{class_names[class_b]}\\n({weight:.1f})'\n",
    "            \n",
    "            # Mock interpolated data\n",
    "            center_a = torch.tensor([2.0, 2.0])  # Circle center\n",
    "            center_b = torch.tensor([-2.0, 2.0])  # Square center\n",
    "            interpolated_center = (1 - weight) * center_a + weight * center_b\n",
    "            \n",
    "            mock_samples = interpolated_center.unsqueeze(0) + 0.3 * torch.randn(10, 2)\n",
    "            \n",
    "            axes[i].scatter(mock_samples[:, 0], mock_samples[:, 1], c=color, alpha=0.7, s=50)\n",
    "            axes[i].set_title(title)\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            axes[i].axis('equal')\n",
    "            axes[i].set_xlim(-3, 3)\n",
    "            axes[i].set_ylim(1, 3)\n",
    "        \n",
    "        plt.suptitle('Class Interpolation (Conceptual)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def demonstrate_hierarchical_conditioning(self):\n",
    "        \"\"\"Demonstrate multi-level conditioning concepts\"\"\"\n",
    "        print(\"=== Hierarchical Conditioning Demo ===\\n\")\n",
    "        \n",
    "        conditioning_hierarchy = {\n",
    "            \"Global Control\": {\n",
    "                \"Level\": \"High-level semantics\",\n",
    "                \"Examples\": [\"Class labels\", \"Style tokens\", \"Global attributes\"],\n",
    "                \"Effect\": \"Overall generation direction\"\n",
    "            },\n",
    "            \"Regional Control\": {\n",
    "                \"Level\": \"Spatial conditioning\", \n",
    "                \"Examples\": [\"Bounding boxes\", \"Segmentation maps\", \"Spatial layouts\"],\n",
    "                \"Effect\": \"Where objects appear\"\n",
    "            },\n",
    "            \"Local Control\": {\n",
    "                \"Level\": \"Fine-grained details\",\n",
    "                \"Examples\": [\"Edge maps\", \"Depth maps\", \"Texture guidance\"],\n",
    "                \"Effect\": \"Surface details and textures\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(\"Modern diffusion models support multiple conditioning levels:\")\n",
    "        for level, info in conditioning_hierarchy.items():\n",
    "            print(f\"\\nüîπ {level}:\")\n",
    "            print(f\"   Level: {info['Level']}\")\n",
    "            print(f\"   Examples: {', '.join(info['Examples'])}\")\n",
    "            print(f\"   Effect: {info['Effect']}\")\n",
    "        \n",
    "        # Visualize hierarchy concept\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        \n",
    "        levels = list(conditioning_hierarchy.keys())\n",
    "        y_positions = [2, 1, 0]\n",
    "        colors = ['lightblue', 'lightgreen', 'lightyellow']\n",
    "        \n",
    "        for i, (level, y_pos, color) in enumerate(zip(levels, y_positions, colors)):\n",
    "            # Draw level box\n",
    "            rect = plt.Rectangle((0.1, y_pos-0.3), 0.8, 0.6, \n",
    "                               facecolor=color, edgecolor='black', alpha=0.7)\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Add text\n",
    "            ax.text(0.5, y_pos, level, ha='center', va='center', \n",
    "                   fontsize=12, fontweight='bold')\n",
    "            \n",
    "            # Add arrows between levels\n",
    "            if i < len(levels) - 1:\n",
    "                ax.arrow(0.5, y_pos-0.4, 0, -0.2, head_width=0.05, head_length=0.05,\n",
    "                        fc='gray', ec='gray')\n",
    "        \n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(-0.5, 2.5)\n",
    "        ax.set_title('Hierarchical Conditioning in Modern Diffusion Models')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def demonstrate_production_considerations(self):\n",
    "        \"\"\"Demonstrate practical considerations for production deployment\"\"\"\n",
    "        print(\"=== Production Deployment Considerations ===\\n\")\n",
    "        \n",
    "        considerations = {\n",
    "            \"Performance Optimization\": [\n",
    "                \"‚Ä¢ Cached embeddings for repeated conditions\",\n",
    "                \"‚Ä¢ Batch processing for multiple samples\", \n",
    "                \"‚Ä¢ Mixed precision training and inference\",\n",
    "                \"‚Ä¢ Model distillation for faster inference\"\n",
    "            ],\n",
    "            \"Quality Control\": [\n",
    "                \"‚Ä¢ Validation metrics for conditioning adherence\",\n",
    "                \"‚Ä¢ Safety filters for inappropriate content\",\n",
    "                \"‚Ä¢ Consistency checks across guidance scales\",\n",
    "                \"‚Ä¢ A/B testing for optimal hyperparameters\"\n",
    "            ],\n",
    "            \"User Experience\": [\n",
    "                \"‚Ä¢ Intuitive guidance scale recommendations\",\n",
    "                \"‚Ä¢ Progressive generation with early previews\",\n",
    "                \"‚Ä¢ Fallback mechanisms for failed generations\",\n",
    "                \"‚Ä¢ Real-time feedback for interactive applications\"\n",
    "            ],\n",
    "            \"Scalability\": [\n",
    "                \"‚Ä¢ Distributed inference for high throughput\",\n",
    "                \"‚Ä¢ Load balancing across multiple models\",\n",
    "                \"‚Ä¢ Efficient memory management for large batches\",\n",
    "                \"‚Ä¢ Auto-scaling based on demand\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        for category, items in considerations.items():\n",
    "            print(f\"üîπ {category}:\")\n",
    "            for item in items:\n",
    "                print(f\"   {item}\")\n",
    "            print()\n",
    "        \n",
    "        print(\"üí° Key Insight: Production systems require extensive engineering beyond the core algorithm!\")\n",
    "    \n",
    "    def showcase_modern_applications(self):\n",
    "        \"\"\"Showcase real-world applications of conditional diffusion\"\"\"\n",
    "        print(\"=== Modern Applications Showcase ===\\n\")\n",
    "        \n",
    "        applications = {\n",
    "            \"Creative AI Tools\": {\n",
    "                \"Examples\": [\"Stable Diffusion\", \"Midjourney\", \"DALL-E\"],\n",
    "                \"Key Features\": [\"Text-to-image\", \"Style transfer\", \"Inpainting\"],\n",
    "                \"Impact\": \"Democratized AI art creation\"\n",
    "            },\n",
    "            \"Content Creation\": {\n",
    "                \"Examples\": [\"Marketing materials\", \"Game assets\", \"Product visualization\"],\n",
    "                \"Key Features\": [\"Brand consistency\", \"Rapid iteration\", \"Custom styles\"],\n",
    "                \"Impact\": \"Accelerated creative workflows\"\n",
    "            },\n",
    "            \"Scientific Applications\": {\n",
    "                \"Examples\": [\"Medical imaging\", \"Material design\", \"Drug discovery\"],\n",
    "                \"Key Features\": [\"Conditional synthesis\", \"Data augmentation\", \"Property control\"],\n",
    "                \"Impact\": \"Enhanced research capabilities\"\n",
    "            },\n",
    "            \"Interactive Media\": {\n",
    "                \"Examples\": [\"Video games\", \"AR/VR\", \"Real-time avatars\"],\n",
    "                \"Key Features\": [\"Real-time generation\", \"User control\", \"Adaptive content\"],\n",
    "                \"Impact\": \"Personalized experiences\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(\"Conditional diffusion has revolutionized multiple industries:\")\n",
    "        for domain, info in applications.items():\n",
    "            print(f\"\\nüöÄ {domain}:\")\n",
    "            print(f\"   Examples: {', '.join(info['Examples'])}\")\n",
    "            print(f\"   Key Features: {', '.join(info['Key Features'])}\")\n",
    "            print(f\"   Impact: {info['Impact']}\")\n",
    "        \n",
    "        print(f\"\\nüåü The Future:\")\n",
    "        print(f\"   ‚Ä¢ Multimodal conditioning (text + image + audio)\")\n",
    "        print(f\"   ‚Ä¢ Real-time interactive generation\")\n",
    "        print(f\"   ‚Ä¢ Personalized AI creative assistants\")\n",
    "        print(f\"   ‚Ä¢ Domain-specific specialized models\")\n",
    "\n",
    "# Demonstrate advanced techniques\n",
    "advanced_demo = AdvancedConditioningDemo(cfg_model, config)\n",
    "\n",
    "# Run demonstrations\n",
    "advanced_demo.demonstrate_guidance_interpolation(class_a=0, class_b=1, num_interpolation_steps=5)\n",
    "advanced_demo.demonstrate_hierarchical_conditioning()\n",
    "advanced_demo.demonstrate_production_considerations()\n",
    "advanced_demo.showcase_modern_applications()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f875b6a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Integration and Final Validation (5 minutes)\n",
    "\n",
    "### Task 7.1: Complete System Integration and Validation\n",
    "\n",
    "**Your Mission**: Integrate all conditional generation approaches and validate the complete system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f50df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_conditional_validation():\n",
    "    \"\"\"\n",
    "    Final validation of the complete conditional generation system\n",
    "    \"\"\"\n",
    "    print(\"=== Comprehensive Conditional Generation Validation ===\\n\")\n",
    "    \n",
    "    validation_results = {\n",
    "        'class_conditional_implemented': False,\n",
    "        'classifier_guidance_implemented': False,\n",
    "        'cfg_implemented': False,\n",
    "        'understanding_demonstrated': False\n",
    "    }\n",
    "    \n",
    "    # Test 1: Class-Conditional Implementation\n",
    "    print(\"1. Validating Class-Conditional Implementation...\")\n",
    "    try:\n",
    "        if 'trainer' in locals():\n",
    "            test_result = trainer.training_step(train_data[:5], train_labels[:5])\n",
    "            if test_result and 'loss' in test_result:\n",
    "                validation_results['class_conditional_implemented'] = True\n",
    "                print(\"   ‚úì Class-conditional training functional\")\n",
    "            else:\n",
    "                print(\"   ‚ùå Implement training_step() method\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Class-conditional trainer not created\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Class-conditional error: {e}\")\n",
    "    \n",
    "    # Test 2: Classifier Guidance Implementation\n",
    "    print(\"2. Validating Classifier Guidance Implementation...\")\n",
    "    try:\n",
    "        if 'guidance_sampler' in locals():\n",
    "            test_gradient = guidance_sampler.compute_classifier_gradient(\n",
    "                torch.randn(3, 2).to(device), target_class=0, t=10)\n",
    "            if test_gradient is not None:\n",
    "                validation_results['classifier_guidance_implemented'] = True\n",
    "                print(\"   ‚úì Classifier guidance functional\")\n",
    "            else:\n",
    "                print(\"   ‚ùå Implement compute_classifier_gradient() method\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Classifier guidance sampler not created\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Classifier guidance error: {e}\")\n",
    "    \n",
    "    # Test 3: CFG Implementation\n",
    "    print(\"3. Validating Classifier-Free Guidance Implementation...\")\n",
    "    try:\n",
    "        if 'cfg_trainer' in locals():\n",
    "            test_result = cfg_trainer.cfg_training_step(train_data[:5], train_labels[:5])\n",
    "            if test_result and 'loss' in test_result:\n",
    "                validation_results['cfg_implemented'] = True\n",
    "                print(\"   ‚úì CFG training functional\")\n",
    "            else:\n",
    "                print(\"   ‚ùå Implement cfg_training_step() method\")\n",
    "        else:\n",
    "            print(\"   ‚ùå CFG trainer not created\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå CFG error: {e}\")\n",
    "    \n",
    "    # Test 4: Understanding Demonstration\n",
    "    print(\"4. Validating Conceptual Understanding...\")\n",
    "    try:\n",
    "        # Check if student ran the limitation demos\n",
    "        if 'limitations_demo' in locals():\n",
    "            validation_results['understanding_demonstrated'] = True\n",
    "            print(\"   ‚úì Unconditional limitations demonstrated\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Run unconditional limitations demo\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Understanding demo error: {e}\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL VALIDATION RESULTS:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for component, status in validation_results.items():\n",
    "        status_str = \"‚úì PASS\" if status else \"‚ùå FAIL\"\n",
    "        component_name = component.replace('_', ' ').title()\n",
    "        print(f\"{component_name}: {status_str}\")\n",
    "    \n",
    "    overall_pass = sum(validation_results.values()) >= 2\n",
    "    print(f\"\\nOverall System Status: {'‚úì FUNCTIONAL' if overall_pass else '‚ùå NEEDS WORK'}\")\n",
    "    \n",
    "    if overall_pass:\n",
    "        print(\"\\nüéâ Congratulations! Your conditional generation system is working!\")\n",
    "        print(\"You've implemented the core techniques that power modern AI art tools!\")\n",
    "    else:\n",
    "        print(\"\\nüîß Keep working on the TODO implementations.\")\n",
    "        print(\"Focus on the training_step() and sampling methods first.\")\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "def demonstrate_conditional_generation_journey():\n",
    "    \"\"\"\n",
    "    Demonstrate the complete journey from unconditional to conditional generation\n",
    "    \"\"\"\n",
    "    print(\"=== Conditional Generation Journey ===\\n\")\n",
    "    \n",
    "    journey_stages = [\n",
    "        \"1. üé≤ Problem: Unconditional generation gives random results\",\n",
    "        \"2. üè∑Ô∏è  Solution 1: Class-conditional - simple embedding approach\",\n",
    "        \"3. üß≠ Solution 2: Classifier guidance - external steering\",\n",
    "        \"4. ‚ö° Solution 3: Classifier-free guidance - modern breakthrough\",\n",
    "        \"5. üöÄ Advanced: Hierarchical and multi-modal conditioning\",\n",
    "        \"6. üè≠ Production: Real-world deployment considerations\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Your journey through conditional diffusion generation:\")\n",
    "    for stage in journey_stages:\n",
    "        print(f\"  {stage}\")\n",
    "    \n",
    "    print(f\"\\nüí° Key insights achieved:\")\n",
    "    print(f\"   ‚Ä¢ Conditional generation solves the control problem\")\n",
    "    print(f\"   ‚Ä¢ Multiple approaches with different trade-offs\")\n",
    "    print(f\"   ‚Ä¢ CFG became the modern standard (Stable Diffusion, DALL-E)\")\n",
    "    print(f\"   ‚Ä¢ Production requires extensive engineering beyond algorithms\")\n",
    "    \n",
    "    print(f\"\\nüåü What this enables:\")\n",
    "    print(f\"   ‚Ä¢ Text-to-image generation (DALL-E, Stable Diffusion)\")\n",
    "    print(f\"   ‚Ä¢ Creative AI tools (Midjourney, Playground AI)\")\n",
    "    print(f\"   ‚Ä¢ Style transfer and artistic applications\")\n",
    "    print(f\"   ‚Ä¢ Controllable content creation\")\n",
    "    \n",
    "    # Create journey visualization\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "    \n",
    "    stages = [\"Problem\", \"Class-Cond\", \"Classifier\", \"CFG\", \"Advanced\", \"Production\"]\n",
    "    stage_colors = ['red', 'lightblue', 'orange', 'lightgreen', 'purple', 'gold']\n",
    "    \n",
    "    # Draw timeline\n",
    "    y_pos = 0.5\n",
    "    stage_width = 0.12\n",
    "    \n",
    "    for i, (stage, color) in enumerate(zip(stages, stage_colors)):\n",
    "        x_pos = 0.1 + i * 0.15\n",
    "        \n",
    "        # Stage circle\n",
    "        circle = plt.Circle((x_pos, y_pos), stage_width/2, \n",
    "                           facecolor=color, edgecolor='black', alpha=0.8)\n",
    "        ax.add_patch(circle)\n",
    "        ax.text(x_pos, y_pos, stage, ha='center', va='center', \n",
    "               fontsize=9, weight='bold')\n",
    "        \n",
    "        # Arrow to next stage\n",
    "        if i < len(stages) - 1:\n",
    "            ax.arrow(x_pos + stage_width/2, y_pos, \n",
    "                    0.15 - stage_width, 0, \n",
    "                    head_width=0.02, head_length=0.01, \n",
    "                    fc='gray', ec='gray')\n",
    "    \n",
    "    # Add evolution annotations\n",
    "    evolutions = [\n",
    "        (0.175, 0.7, \"Random\\nGeneration\"),\n",
    "        (0.325, 0.3, \"Simple\\nControl\"),\n",
    "        (0.475, 0.7, \"External\\nSteering\"),\n",
    "        (0.625, 0.3, \"Unified\\nModel\"),\n",
    "        (0.775, 0.7, \"Multi-Modal\\nControl\"),\n",
    "        (0.925, 0.3, \"Real-World\\nSystems\")\n",
    "    ]\n",
    "    \n",
    "    for x, y, text in evolutions:\n",
    "        ax.text(x, y, text, ha='center', va='center', fontsize=8,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightyellow', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('Evolution of Conditional Diffusion Generation', fontsize=16, weight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_final_summary():\n",
    "    \"\"\"Create a comprehensive summary of conditional generation approaches\"\"\"\n",
    "    print(\"=== Final Summary: Conditional Generation Mastery ===\\n\")\n",
    "    \n",
    "    # Method comparison table\n",
    "    methods_summary = {\n",
    "        \"Approach\": [\"Class-Conditional\", \"Classifier Guidance\", \"Classifier-Free\"],\n",
    "        \"Training\": [\"Conditional only\", \"Separate classifier\", \"Joint training\"],\n",
    "        \"Sampling\": [\"1 forward pass\", \"2 passes + gradients\", \"2 forward passes\"],\n",
    "        \"Flexibility\": [\"Fixed classes\", \"Any classifier\", \"Learned conditions\"],\n",
    "        \"Speed\": [\"Fastest\", \"Slowest\", \"Medium\"],\n",
    "        \"Quality\": [\"Good\", \"Excellent\", \"Excellent\"],\n",
    "        \"Modern Use\": [\"Limited\", \"Research\", \"Production Standard\"]\n",
    "    }\n",
    "    \n",
    "    print(\"üìä Method Comparison Summary:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Print table header\n",
    "    print(f\"{'Aspect':<15} {'Class-Cond':<12} {'Classifier':<12} {'CFG':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Print table rows\n",
    "    aspects = [\"Training\", \"Sampling\", \"Flexibility\", \"Speed\", \"Quality\", \"Modern Use\"]\n",
    "    for i, aspect in enumerate(aspects):\n",
    "        row = f\"{aspect:<15} {methods_summary[list(methods_summary.keys())[0]][i+1]:<12} \"\n",
    "        row += f\"{methods_summary[list(methods_summary.keys())[0]][i+1]:<12} \"\n",
    "        row += f\"{methods_summary[list(methods_summary.keys())[0]][i+1]:<12}\"\n",
    "        print(row)\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(f\"\\nüèÜ Winner for Modern Applications: Classifier-Free Guidance\")\n",
    "    print(f\"   ‚Ä¢ Powers all major text-to-image models\")\n",
    "    print(f\"   ‚Ä¢ Best balance of quality, flexibility, and practicality\")\n",
    "    print(f\"   ‚Ä¢ Enables complex multi-modal conditioning\")\n",
    "    \n",
    "    print(f\"\\nüîÆ Future Directions:\")\n",
    "    print(f\"   ‚Ä¢ Real-time interactive generation\")\n",
    "    print(f\"   ‚Ä¢ Multimodal conditioning (text + image + audio + 3D)\")\n",
    "    print(f\"   ‚Ä¢ Personalized models that adapt to user preferences\")\n",
    "    print(f\"   ‚Ä¢ Specialized domain models (medical, scientific, creative)\")\n",
    "    \n",
    "    print(f\"\\nüéØ Key Takeaways:\")\n",
    "    print(f\"   ‚Ä¢ Conditional generation solves the control problem in diffusion models\")\n",
    "    print(f\"   ‚Ä¢ Different approaches offer different trade-offs\")\n",
    "    print(f\"   ‚Ä¢ CFG has become the foundation of modern AI creativity tools\")\n",
    "    print(f\"   ‚Ä¢ Implementation details matter for production deployment\")\n",
    "\n",
    "# Run final validation and demonstrations\n",
    "validation_results = comprehensive_conditional_validation()\n",
    "demonstrate_conditional_generation_journey()\n",
    "create_final_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéì LAB 6 COMPLETE: Conditional Generation Mastery Achieved!\")\n",
    "print(\"=\"*80)\n",
    "print(\"You've learned the techniques that power modern AI art and content creation!\")\n",
    "print(\"From DALL-E to Stable Diffusion, you now understand the core algorithms.\")\n",
    "print(\"Ready to build the next generation of creative AI tools? üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c4081",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "---\n",
    "\n",
    "## Implementation Checklist\n",
    "\n",
    "### Core Conditional Functions (Students Implement):\n",
    "\n",
    "**‚úÖ Essential TODOs:**\n",
    "- [ ] `training_step()` (Class-Conditional) - Basic conditional training objective\n",
    "- [ ] `ddim_step()` (Class-Conditional) - Class-conditional DDIM sampling step\n",
    "- [ ] `sample_class_conditional()` - Complete class-conditional generation\n",
    "- [ ] `compute_classifier_gradient()` - Gradient computation for classifier guidance\n",
    "- [ ] `classifier_guided_step()` - Single step with classifier guidance\n",
    "- [ ] `sample_with_classifier_guidance()` - Complete classifier-guided sampling\n",
    "- [ ] `cfg_training_step()` - CFG training with conditioning dropout\n",
    "- [ ] `cfg_step()` - CFG sampling step with guidance formula\n",
    "- [ ] `sample_cfg()` - Complete classifier-free guidance sampling\n",
    "\n",
    "**‚úÖ Provided Starter Code:**\n",
    "- [ ] All U-Net architectures and model definitions\n",
    "- [ ] Noise-aware classifier implementation\n",
    "- [ ] Complete visualization and analysis frameworks\n",
    "- [ ] Comparison and benchmarking systems\n",
    "- [ ] Advanced conditioning demonstrations\n",
    "- [ ] Production considerations and deployment guidance\n",
    "\n",
    "---\n",
    "\n",
    "## Submission Requirements\n",
    "\n",
    "### What to Submit\n",
    "\n",
    "Submit your completed Jupyter notebook (.ipynb file) with:\n",
    "\n",
    "**‚úÖ Class-Conditional Implementation:**\n",
    "- Complete training objective with class embedding injection\n",
    "- DDIM sampling modified for class conditioning\n",
    "- Demonstration of controlled class generation\n",
    "\n",
    "**‚úÖ Classifier Guidance Implementation:**\n",
    "- Noise-aware classifier training and gradient computation\n",
    "- Classifier-guided sampling with adjustable guidance scales\n",
    "- Analysis of guidance strength effects on quality and diversity\n",
    "\n",
    "**‚úÖ Classifier-Free Guidance Implementation:**\n",
    "- Joint training for conditional and unconditional generation\n",
    "- CFG sampling with the guidance formula implementation\n",
    "- Comparison of different guidance scales and their effects\n",
    "\n",
    "**‚úÖ Comprehensive Analysis:**\n",
    "- Comparison between all three conditioning approaches\n",
    "- Trade-off analysis: speed vs quality vs flexibility\n",
    "- Understanding of when to use each method\n",
    "\n",
    "**‚úÖ Advanced Understanding:**\n",
    "- Demonstration of unconditional generation limitations\n",
    "- Analysis of production deployment considerations\n",
    "- Connection between mathematical formulations and practical implementations\n",
    "\n",
    "**‚úÖ Documentation and Insights:**\n",
    "- Clear explanations of implementation choices\n",
    "- Discussion of real-world applications and impact\n",
    "- Understanding of how these techniques power modern AI art tools\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Reference: Key Implementation Formulas\n",
    "\n",
    "### For Implementation Reference:\n",
    "\n",
    "**Class-Conditional Training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610382a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified training objective with class conditioning\n",
    "# L = E[||Œµ - Œµ_Œ∏(x_t, y, t)||¬≤]\n",
    "predicted_noise = model(x_noisy, class_labels, t)\n",
    "loss = F.mse_loss(predicted_noise, actual_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419712f8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Classifier Guidance Formula:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ŒµÃÉ = Œµ_Œ∏(x_t, t) - œâ‚àö(1-·æ±_t) ‚àá_x log p(y|x_t)\n",
    "unconditional_noise = model(x_t, t)\n",
    "classifier_grad = compute_gradient(classifier, x_t, target_class, t)\n",
    "guided_noise = unconditional_noise - guidance_scale * math.sqrt(1 - alpha_cumprod_t) * classifier_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b308066",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**CFG Training with Dropout:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b1f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly drop conditioning during training\n",
    "if torch.rand(1) < dropout_prob:\n",
    "    class_labels = None  # Unconditional training\n",
    "predicted_noise = model(x_noisy, class_labels, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb6af69",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**CFG Sampling Formula:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927417df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ŒµÃÉ = (1+œâ)Œµ_cond - œâŒµ_uncond\n",
    "conditional_noise = model(x_t, class_labels, t)\n",
    "unconditional_noise = model(x_t, None, t)\n",
    "guided_noise = (1 + guidance_scale) * conditional_noise - guidance_scale * unconditional_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8b33f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Implementation Issues & Solutions\n",
    "\n",
    "### Debugging Tips:\n",
    "\n",
    "**Class Embedding Issues:**\n",
    "- Ensure class labels are within valid range [0, num_classes-1]\n",
    "- Check that embedding dimensions match other embeddings\n",
    "- Verify proper combination of time and class embeddings\n",
    "\n",
    "**Guidance Scale Problems:**\n",
    "- Start with guidance_scale=1.0 for debugging\n",
    "- Scale=0.0 should give unconditional results\n",
    "- Very high scales (>10) may cause artifacts or instability\n",
    "\n",
    "**CFG Training Issues:**\n",
    "- Verify dropout is applied correctly during training only\n",
    "- Check that model handles None class_labels properly\n",
    "- Ensure null token is properly defined and used\n",
    "\n",
    "**Sampling Convergence:**\n",
    "- Reduce number of steps for faster debugging\n",
    "- Check that noise predictions are reasonable (not NaN/inf)\n",
    "- Verify timestep scheduling is correct\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
